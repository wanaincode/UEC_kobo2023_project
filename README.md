### ç”»åƒèªè­˜æŠ€è¡“ã‚’æ´»ç”¨ã—ãŸå†·è”µåº«å†…é£Ÿæè‡ªå‹•åˆ¤åˆ¥ã‚·ã‚¹ãƒ†ãƒ ã®é–‹ç™º  
- æƒ…å ±å‡¦ç†ç¬¬86å›žå¤§ä¼š å­¦ç”Ÿå¥¨åŠ±è³ž å—è³žä½œå“
- AI Food Recognizer with GroundingDINO + SAM + CLIP

This project is the final work for the elective course **"æƒ…å ±å·¥å­¦å·¥æˆ¿ (Information Engineering Workshop)"** at **The University of Electro-Communications (é›»æ°—é€šä¿¡å¤§å­¦)**, under the I-Class curriculum for Information Science students.

ðŸ§‘â€ðŸ’¼ Theme:  
**ã€Œå·¨å¤§ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã„ã“ãªã›ï¼å¤§è¦æ¨¡æ·±å±¤å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’æ´»ç”¨ã—ãŸç”»åƒèªè­˜ãƒ»ç”Ÿæˆã€**  
("Master the Giant Models! Image Recognition and Generation with Large-Scale Deep Learning Models")

ðŸ‘¨â€ðŸ’» Authors:  
- Mengchi Wang (çŽ‹ å­Ÿçª)  
- Junwen Chen (é™³ ä¿Šæ–‡) â€“ Teaching Assistant  
- Prof. Keiji Yanai (æŸ³äº• å•“å¸) â€“ Faculty Advisor

---

This project integrates multiple state-of-the-art vision and language models to detect, segment, and recognize food items in images, and optionally fetch their names and calorie information using the OpenAI API.

---

ðŸ” Overview

This pipeline combines:
- **GroundingDINO** â€“ for open-vocabulary object detection with text prompts  
- **Segment Anything (SAM)** â€“ for precise image segmentation  
- **CLIP** â€“ for embedding extracted image regions into a semantic space  
- **OpenAI GPT-4o API** â€“ to describe the recognized object and return its calorie (optional)

Ideal for building intelligent food loggers, AR food labeling, and diet tracking systems.

---

ðŸ§  Architecture

     +----------------+          +---------------------+
     |   Input Image  |  --->    |  GroundingDINO      |
     +----------------+          +---------------------+
                                          |
                                          v
                            +---------------------------+
                            | Segment Anything (SAM)    |
                            +---------------------------+
                                          |
                                          v
                            +---------------------------+
                            | CLIP Feature Extraction   |
                            +---------------------------+
                                          |
                  +--------------------+  v
                  | Feature Matching   | ---> Object Label
                  +--------------------+
                                          |
                                          v
                        (Optional) Call OpenAI GPT-4 API
                        to retrieve object name & calorie



---

ðŸ“Œ Features
- Text-based object detection using GroundingDINO
- Image segmentation using SAM (Segment Anything)
- Feature embedding and similarity matching with CLIP
- Optional: retrieve object description and calories via OpenAI GPT-4 Vision
- Feature registration and one-shot object recognition
- Exportable visual results with bounding boxes and labels

---

ðŸš€ Getting Started

1. Install Dependencies

Install Python dependencies and download model checkpoints for:
- GroundingDINO
- SAM (ViT-H)
- CLIP (ViT-B/32)
- OpenAI SDK (optional)

```python
pip install -r requirements.txt
```

---

2. Run as Needed

Choose the appropriate script depending on your needs:
-  ground_dino_sam_clip.ipynb:
Interactive notebook for testing the combination of GroundingDINO, SAM, and CLIP.
- ðŸ’» demo_ver2_without UI.py:
Terminal-based script. You manually type the object name, extract features, and recognize.
- demo_ver3_UI.py (Recommended):
OpenCV GUI-based version that lets you input object names and trigger feature extraction/recognition via buttons.
- API_get_food_info.py:
Upload test_item.jpg into the folder, and this script will send it to GPT-4 Vision using your own OpenAI API key to return the food name and calorie.

ðŸ“‚ Directory Structure
```
.
â”œâ”€â”€ GroundingDINO/                # GroundingDINO model & configs
â”œâ”€â”€ segment-anything/             # SAM model
â”œâ”€â”€ saved_obj_img/                # Registered training images
â”œâ”€â”€ extract_saved_obj_feature/    # Feature vectors
â”œâ”€â”€ test_img/                     # Input test images
â”œâ”€â”€ recognized_results/           # Prediction result images
â”œâ”€â”€ main.py                       # Main logic script
â”œâ”€â”€ demo_ver3_UI.py               # OpenCV UI version
â”œâ”€â”€ API_get_food_info.py          # OpenAI calorie recognition
â””â”€â”€ requirements.txt
```

---

3. Run Recognition

Put test images in test_img/, and run the recognition pipeline:
```python
recognize_pipeline(model, predictor, extractor, obj_features, './test_img/example.jpg', box_threshold=0.15, text_threshold=0.15)
```
The results will be saved under recognized_results/.

---

ðŸ“‚ Directory Structure
```
.
â”œâ”€â”€ GroundingDINO/                # GroundingDINO model & configs
â”œâ”€â”€ segment-anything/             # SAM model
â”œâ”€â”€ saved_obj_img/                # Registered training images
â”œâ”€â”€ extract_saved_obj_feature/    # Feature vectors
â”œâ”€â”€ test_img/                     # Input test images
â”œâ”€â”€ recognized_results/           # Prediction result images
â”œâ”€â”€ main.py                       # Main logic script
â””â”€â”€ utils/                        # (Optional) helper functions
```

---

ðŸ”‘ API Integration (Optional)

To fetch object name and calorie:

1. Set your OpenAI API key:

```python
client = OpenAI(api_key="your-api-key")
```

2. The model sends a base64-encoded cropped image to GPT-4 Vision, requesting name and calorie in a defined format.

---

ðŸ“¸ Example Results

[![Watch the demo](https://img.youtube.com/vi/WM_rVHsI6sQ/maxresdefault.jpg)](https://www.youtube.com/watch?v=WM_rVHsI6sQ)

> Click the image above to watch a demo on YouTube.

---

ðŸ“„ License

This project is released under the MIT License.

